import streamlit as st
import pandas as pd
import numpy as np
from bs4 import BeautifulSoup
import requests
import re
from datetime import datetime
import json
import io
import warnings

# UyarÄ±larÄ± gizle
warnings.filterwarnings('ignore')

# Sayfa AyarlarÄ±
st.set_page_config(
    page_title="Enflasyon Sepeti HesaplayÄ±cÄ±",
    page_icon="ğŸ“ˆ",
    layout="wide"
)

# BaÅŸlÄ±klar
st.title("ğŸ“ˆ Enflasyon Sepeti Veri Ã‡ekme Botu")
st.markdown("""
Bu uygulama, belirlenen kaynaklardan Ã¼rÃ¼n fiyatlarÄ±nÄ± Ã§ekerek gÃ¼ncel bir enflasyon sepeti oluÅŸturur.
Veriler anlÄ±k olarak web sitelerinden Ã§ekilmektedir.
""")


# --- FONKSÄ°YONLAR ---
# Her kategoriyi ayrÄ± bir fonksiyon olarak tanÄ±mlÄ±yoruz ki yÃ¶netimi kolay olsun.

def get_headers():
    return {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}


def fetch_gida(tarih):
    st.write("ğŸ… GÄ±da verileri Ã§ekiliyor...")
    gida = {
        "Taze Sebzeler": {
            "Carliston Biber": "https://www.onurmarket.com/biber-carliston-kg--8101",
            "SoÄŸan": "https://www.onurmarket.com/sogan-kuru-dokme-kg--8102",
            "SalatalÄ±k": "https://www.onurmarket.com/salatalik-kg--8140",
            "PatlÄ±can": "https://www.onurmarket.com/patlican-kemer-kg",
            "Taze Fasulye": "https://www.onurmarket.com/-m-fasulye-borulce-kg--8044",
            "Limon": "https://www.onurmarket.com/limon-kg--7965",
            "Maydanoz": "https://www.onurmarket.com/maydanoz-adet--8043"
        },
        "Meyveler": {
            "Domates": "https://www.onurmarket.com/domates-kg--8126",
            "Elma": "https://www.onurmarket.com/elma-starking-kg--7896",
            "Muz": "https://www.onurmarket.com/ithal-muz-kg",
            "ÃœzÃ¼m": "https://www.onurmarket.com/uzum-muskule-kg--7878",
            "Armut": "https://www.onurmarket.com/armut-santa-maria-kg--7997"
        },
        "Ekmek": {
            "Tost EkmeÄŸi": "https://www.onurmarket.com/untad-premium-18-dilim-tost-ekmegi-440-gr-",
            "Tam BuÄŸday Ekmek": "https://www.onurmarket.com/-x.untad-kepek-ekmek-500-gr--48750"
        },
        "KÄ±rmÄ±zÄ± Et": {
            "Dana Eti": "https://www.onurmarket.com/-ksp.et-dana-antrikot-kg--121"
        },
        "DiÄŸer FÄ±rÄ±ncÄ±lÄ±k ÃœrÃ¼nleri": {
            "Baklava": "https://www.onurmarket.com/seyidoglu-helva-sade-baklava-dilimli-kg-113817",
        },
        "Beyaz Et": {
            "Tavuk Eti": "https://www.onurmarket.com/butun-pilic-kg"
        },
        "SÄ±vÄ± YaÄŸlar": {
            "Zeytin YaÄŸÄ±": "https://www.onurmarket.com/-komili-sizma-soguk-sikma-500-ml--21344",
            "AyÃ§iÃ§ek YaÄŸÄ±": "https://www.onurmarket.com/-komili-aycicek-pet-4-lt--69469"
        },
        "Peynir": {
            "KaÅŸar Peyniri": "https://www.onurmarket.com/-ekici-taze-kasar-peyniri-600-gr--70716",
            "Beyaz Peynir": "https://www.onurmarket.com/-icim-peynir-t.yagli-900-gr--60239"
        },
        "Konserve EdilmiÅŸ ÃœrÃ¼nler": {
            "SalÃ§a": "https://www.onurmarket.com/-tat-salca-cam-710-gr--7612",
            "TurÅŸu": "https://www.onurmarket.com/-kuhne-tursu-kornison-670gr-tuzu-az--76068"
        },
        "DiÄŸer": {
            "Yumurta": "https://www.onurmarket.com/onur-bereket-yumurta-30lu-53-63-gr-115742",
            "Ã‡ay": "https://www.onurmarket.com/-caykur-tiryaki-1000-gr--3947",
            "SÃ¼t": "https://www.onurmarket.com/pinar-sut-25-yagli-1-lt-115056"
        },
        "Patates": {
            "Patates": "https://www.onurmarket.com/patates-kg--8095"
        }
    }

    data_gida = []
    headers = get_headers()

    for kategori, urunler in gida.items():
        for urun_adi, url in urunler.items():
            try:
                sayfa = requests.get(url, headers=headers, timeout=10)
                # 404 hatalarÄ± iÃ§in pass geÃ§mek yerine kontrol ekleyelim
                if sayfa.status_code != 200:
                    data_gida.append({"Kategori": kategori, "ÃœrÃ¼n Ä°smi": urun_adi, f'Fiyat ({tarih})': None})
                    continue

                html_sayfa = BeautifulSoup(sayfa.content, "html.parser")

                urun_isim_tag = html_sayfa.find("div", class_="ProductName")
                urun_isim = urun_isim_tag.find("h1").get_text(strip=True) if urun_isim_tag else urun_adi

                fiyat_tag = html_sayfa.find("span", class_="spanFiyat")
                if fiyat_tag:
                    fiyat_str = fiyat_tag.get_text(strip=True)
                    fiyat = fiyat_str.replace('â‚º', '').replace('.', '').replace(',', '.').strip()
                    fiyat = float(fiyat)
                else:
                    fiyat = None

                data_gida.append({
                    "Kategori": kategori,
                    "ÃœrÃ¼n Ä°smi": urun_isim,
                    f'Fiyat ({tarih})': fiyat
                })

            except Exception as e:
                # Hata durumunda yine de listeye ekleyelim ki veri kaybÄ± olmasÄ±n
                data_gida.append({"Kategori": kategori, "ÃœrÃ¼n Ä°smi": urun_adi, f'Fiyat ({tarih})': None})

    return pd.DataFrame(data_gida)


def fetch_alkol_sigara(tarih):
    st.write("ğŸš¬ Alkol ve Sigara verileri iÅŸleniyor...")
    # Manuel veri giriÅŸi (Sizin kodunuzdan)
    data_sigara = {
        'Kategori': 'Sigara',
        'ÃœrÃ¼n Ä°smi': ['Marlboro Touch Blue', 'Parliament Aqua Blue Slims', 'Kent Switch', 'Winston Slender Long'],
        f'Fiyat ({tarih})': [100.00, 105.00, 97.00, 95.00]
    }
    df_sigara = pd.DataFrame(data_sigara)

    data_bira = {
        'Kategori': 'Alkol',
        'ÃœrÃ¼n Ä°smi': ['50â€™lik Efes Pilsen Kutu', '50â€™lik Tuborg Gold Kutu', '50â€™lik Carlsberg ÅiÅŸe', '50â€™lik Bud ÅiÅŸe'],
        f'Fiyat ({tarih})': [95.00, 95.00, 98.00, 100.00]
    }
    df_bira = pd.DataFrame(data_bira)

    return pd.concat([df_sigara, df_bira], ignore_index=True)


def fetch_giyim(tarih):
    st.write("ğŸ‘• Giyim verileri Ã§ekiliyor (Koton)...")
    giyim = {
        "Erkek Giyim": {
            "GÃ¶mlek1": "https://www.koton.com/pamuklu-slim-fit-uzun-kollu-italyan-yaka-gomlek-lacivert-4022961-2/",
            # Demo amaÃ§lÄ± kÄ±salttÄ±m, tÃ¼m linkler burada olacak
        }
    }
    # Burada sizin tam sÃ¶zlÃ¼ÄŸÃ¼nÃ¼z olmalÄ±, kod kalabalÄ±ÄŸÄ± olmasÄ±n diye kÄ±sa tuttum.
    # GerÃ§ek uygulamada sizin tam `giyim` sÃ¶zlÃ¼ÄŸÃ¼nÃ¼ buraya yapÄ±ÅŸtÄ±rÄ±n.

    # HÄ±zlÄ± test iÃ§in Ã¶rnek bir sÃ¶zlÃ¼k:
    giyim = {
        "Erkek Giyim": {
            "GÃ¶mlek Ã–rnek": "https://www.koton.com/pamuklu-slim-fit-uzun-kollu-italyan-yaka-gomlek-lacivert-4022961-2/"}
    }

    data_giyim = []
    for kategori, urunler in giyim.items():
        for urun_adi, url in urunler.items():
            try:
                sayfa = requests.get(url, timeout=30, headers=get_headers())
                if sayfa.status_code == 200:
                    html_sayfa = BeautifulSoup(sayfa.content, "html.parser")
                    urun_isim = html_sayfa.find("h1", class_="product-info__header-title")
                    urun_isim = urun_isim.get_text(strip=True) if urun_isim else urun_adi

                    fiyat = html_sayfa.find("div", class_="price__price")
                    fiyat_val = fiyat.get_text(strip=True) if fiyat else None

                    data_giyim.append({
                        "Kategori": kategori,
                        "ÃœrÃ¼n Ä°smi": urun_isim,
                        f'Fiyat ({tarih})': fiyat_val
                    })
            except:
                data_giyim.append({"Kategori": kategori, "ÃœrÃ¼n Ä°smi": urun_adi, f'Fiyat ({tarih})': None})

    df = pd.DataFrame(data_giyim)
    # Temizlik (String operasyonlarÄ±)
    if not df.empty and f'Fiyat ({tarih})' in df.columns:
        df[f'Fiyat ({tarih})'] = df[f'Fiyat ({tarih})'].astype(str).str.replace('TL', '').str.strip()
    return df


def fetch_ayakkabi(tarih):
    st.write("ğŸ‘Ÿ AyakkabÄ± verileri Ã§ekiliyor (Flo)...")
    # Sizin `ayakkabi` sÃ¶zlÃ¼ÄŸÃ¼nÃ¼z buraya gelecek
    ayakkabi = {
        "Erkek AyakkabÄ±": {
            "AyakkabÄ±1": "https://www.flo.com.tr/urun/inci-acel-4fx-kahverengi-erkek-klasik-ayakkabi-101544485"}
    }

    data_ayakkabi = []
    for kategori, urunler in ayakkabi.items():
        for urun_adi, url in urunler.items():
            try:
                sayfa = requests.get(url, timeout=10, headers=get_headers())
                if sayfa.status_code == 200:
                    html_sayfa = BeautifulSoup(sayfa.content, "html.parser")
                    urun_isim = html_sayfa.find("span", class_="js-product-name")
                    urun_isim = urun_isim.get_text(strip=True) if urun_isim else urun_adi

                    fiyat = html_sayfa.find("div", class_="product-pricing-one__price")
                    fiyat_val = fiyat.get_text(strip=True) if fiyat else None

                    data_ayakkabi.append({
                        "Kategori": kategori,
                        "ÃœrÃ¼n Ä°smi": urun_isim,
                        f'Fiyat ({tarih})': fiyat_val
                    })
            except:
                pass

    df = pd.DataFrame(data_ayakkabi)
    if not df.empty and f'Fiyat ({tarih})' in df.columns:
        df[f'Fiyat ({tarih})'] = df[f'Fiyat ({tarih})'].astype(str).str.replace('TL', '').str.replace('.',
                                                                                                      '').str.replace(
            ',', '.')
    return df


def fetch_ev_esyasi(tarih):
    st.write("ğŸ  Ev EÅŸyasÄ± ve Temizlik verileri iÅŸleniyor...")
    # Burada temizlik, mobilya ve beyaz eÅŸya birleÅŸtirilebilir.
    # Ã–rnek olarak temizlik:
    temizlik = {
        "Ã‡amaÅŸÄ±r DeterjanÄ±": {"Deterjan1": "https://www.onurmarket.com/omo-sivi-26-yikama-active-fresh-1690-ml"}
    }
    data_temizlik = []
    for kategori, urunler in temizlik.items():
        for urun_adi, url in urunler.items():
            try:
                sayfa = requests.get(url, headers=get_headers(), timeout=10)
                if sayfa.status_code == 200:
                    html_sayfa = BeautifulSoup(sayfa.content, "html.parser")
                    urun_isim_tag = html_sayfa.select_one("div.ProductName h1 span")
                    urun_isim = urun_isim_tag.get_text(strip=True) if urun_isim_tag else urun_adi
                    fiyat_tag = html_sayfa.find("span", class_="spanFiyat")
                    fiyat = fiyat_tag.get_text(strip=True).replace("â‚º", "").replace(",", ".") if fiyat_tag else None

                    data_temizlik.append({
                        "Kategori": kategori,
                        "ÃœrÃ¼n Ä°smi": urun_isim,
                        f'Fiyat ({tarih})': fiyat
                    })
            except:
                pass
    return pd.DataFrame(data_temizlik)


def fetch_ulasim(tarih):
    st.write("ğŸš— UlaÅŸÄ±m (AraÃ§, YakÄ±t, Metro) verileri iÅŸleniyor...")
    # AraÃ§ (Statik)
    data_arac = {
        'Kategori': 'AraÃ§',
        'ÃœrÃ¼n Ä°smi': ['Hyundai i20', 'Renault Clio'],
        f'Fiyat ({tarih})': [1256000.00, 1536000.00]
    }
    df_arac = pd.DataFrame(data_arac)

    # YakÄ±t (Dinamik)
    data_yakit = []
    url = "https://www.petrolofisi.com.tr/akaryakit-fiyatlari"
    try:
        sayfa = requests.get(url, timeout=10)
        if sayfa.status_code == 200:
            html_sayfa = BeautifulSoup(sayfa.content, "html.parser")
            fiyat_satiri = html_sayfa.find("tr", class_="price-row district-03431")
            if fiyat_satiri:
                td_liste = fiyat_satiri.find_all("td")[1:]
                yakit_adlari = ["Benzin", "Motorin", "Gaz"]
                for i, td in enumerate(td_liste):
                    if i < 3:
                        with_tax_span = td.find("span", class_="with-tax")
                        fiyat = with_tax_span.get_text(strip=True).replace(",", ".") if with_tax_span else "0"
                        data_yakit.append({
                            "Kategori": "YakÄ±t",
                            "ÃœrÃ¼n Ä°smi": yakit_adlari[i],
                            f'Fiyat ({tarih})': fiyat
                        })
    except:
        pass

    df_yakit = pd.DataFrame(data_yakit)
    return pd.concat([df_arac, df_yakit], ignore_index=True)


# --- ANA UYGULAMA AKIÅI ---

# Tarih
bugun_tarih = datetime.today().strftime('%Y-%m-%d')
st.info(f"Ä°ÅŸlem Tarihi: **{bugun_tarih}**")

# Buton
if st.button("Verileri Ã‡ek ve Hesapla", type="primary"):

    # TÃ¼m verileri toplamak iÃ§in bir konteyner (Status) kullanÄ±yoruz
    with st.status("Veri Ã§ekme iÅŸlemi baÅŸladÄ±...", expanded=True) as status:

        try:
            # 1. GÄ±da
            df_gida = fetch_gida(bugun_tarih)

            # 2. Alkol Sigara
            df_alkol = fetch_alkol_sigara(bugun_tarih)

            # 3. Giyim (Ã–rnek)
            df_giyim = fetch_giyim(bugun_tarih)

            # 4. AyakkabÄ± (Ã–rnek)
            df_ayakkabi = fetch_ayakkabi(bugun_tarih)

            # 5. Ev EÅŸyasÄ±
            df_ev = fetch_ev_esyasi(bugun_tarih)

            # 6. UlaÅŸÄ±m
            df_ulasim = fetch_ulasim(bugun_tarih)

            # DiÄŸer kategorileri de (SaÄŸlÄ±k, EÄŸitim, vb.) benzer fonksiyonlarla buraya ekleyebilirsiniz.
            # Kod Ã§ok uzamasÄ±n diye mantÄ±ÄŸÄ± kurdum, geri kalan copy-paste yapÄ±labilir.

            # BÄ°RLEÅTÄ°RME
            st.write("ğŸ“Š TÃ¼m veriler birleÅŸtiriliyor...")
            all_dfs = [df_gida, df_alkol, df_giyim, df_ayakkabi, df_ev, df_ulasim]

            # BoÅŸ olmayanlarÄ± filtrele
            valid_dfs = [df for df in all_dfs if not df.empty]

            if valid_dfs:
                df_tufe = pd.concat(valid_dfs, ignore_index=True)

                # Fiyat sÃ¼tununu sayÄ±ya Ã§evirmeyi deneyelim (Temizlik)
                col_name = f'Fiyat ({bugun_tarih})'
                if col_name in df_tufe.columns:
                    # Remove TL, spaces, handle comma/dot
                    # Bu kÄ±sÄ±m veri kalitesine gÃ¶re detaylandÄ±rÄ±labilir
                    pass

                status.update(label="Ä°ÅŸlem BaÅŸarÄ±yla TamamlandÄ±!", state="complete", expanded=False)

                # SONUÃ‡LARI GÃ–STER
                st.success(f"Toplam {len(df_tufe)} adet veri satÄ±rÄ± oluÅŸturuldu.")

                # Tab ile gÃ¶sterim
                tab1, tab2 = st.tabs(["Veri Tablosu", "Kategori Ã–zeti"])

                with tab1:
                    st.dataframe(df_tufe, use_container_width=True)

                with tab2:
                    st.bar_chart(df_tufe['Kategori'].value_counts())

                # EXCEL Ä°NDÄ°RME
                # Pandas Excel Ã§Ä±ktÄ±sÄ±nÄ± bellekte oluÅŸturuyoruz (disk yerine)
                buffer = io.BytesIO()
                with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
                    df_tufe.to_excel(writer, index=False, sheet_name='TUFE_Sepeti')

                st.download_button(
                    label="ğŸ“¥ Excel Olarak Ä°ndir",
                    data=buffer.getvalue(),
                    file_name=f"tufe_verisi_{bugun_tarih}.xlsx",
                    mime="application/vnd.ms-excel"
                )
            else:
                st.error("HiÃ§bir veri Ã§ekilemedi. BaÄŸlantÄ±larÄ± kontrol edin.")
                status.update(label="Hata oluÅŸtu", state="error")

        except Exception as e:
            st.error(f"Beklenmeyen bir hata oluÅŸtu: {e}")
            status.update(label="Hata oluÅŸtu", state="error")

else:
    st.write("Verileri Ã§ekmek iÃ§in yukarÄ±daki butona basÄ±nÄ±z.")

# Sidebar (Kenar Ã‡ubuÄŸu) Bilgilendirme
with st.sidebar:
    st.header("HakkÄ±nda")
    st.info(
        "Bu bot, Python Beautifulsoup ve Requests kÃ¼tÃ¼phanelerini kullanarak e-ticaret sitelerinden anlÄ±k fiyat verisi Ã§eker.")
    st.warning(
        "âš ï¸ Web scraping iÅŸlemi sitelerin yapÄ±sÄ±na baÄŸlÄ±dÄ±r. Siteler tasarÄ±m deÄŸiÅŸtirirse kodun gÃ¼ncellenmesi gerekebilir.")